{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Load training set\n",
    "training_set = pd.read_csv(\"https://raw.githubusercontent.com/eliiza/ml-training-data/master/housing_price_data/training_data.csv\")\n",
    "\n",
    "# Use same evaluate_model function as before\n",
    "def evaluate_model(model_fn, print_result=False):\n",
    "    '''\n",
    "    Consumes a function model_fn\n",
    "    and evaluates its predictive accuracy against \n",
    "    the housing prices test set.\n",
    "    We have included a switch for the output to be a more human readable\n",
    "    printed version or the uncurtailed floating point value of the average.\n",
    "    '''\n",
    "    test_data = pd.read_csv(\"https://raw.githubusercontent.com/eliiza/ml-training-data/master/housing_price_data/test_data.csv\")\n",
    "    actual_values = test_data['SalePrice']\n",
    "    # Pass in all columns except SalePrice\n",
    "    test_input = test_data.filter(regex='^(?!SalePrice$).*')\n",
    "    predicted_saleprice = model_fn(test_input)\n",
    "    mae = np.mean(np.abs(predicted_saleprice-actual_values))\n",
    "    if print_result:\n",
    "        return print(\"The model is inaccurate by $%.2f on average.\" % mae)\n",
    "    else:\n",
    "        return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric Features\n",
    "\n",
    "If our columns are numeric, it's straightforward to add them to a linear regression model. \n",
    "\n",
    "Below we are adding an extra feature to the simple `OverallQual` model: `GrLivArea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression model function based on 'OverallQual' and 'GrLivArea'\n",
    "# returns the model predictions\n",
    "    \n",
    "# Create features data frame and train model    \n",
    "training_features = training_set[['OverallQual','GrLivArea']]\n",
    "predictor = linear_model.LinearRegression()\n",
    "predictor.fit(training_features, training_set['SalePrice'])\n",
    "    \n",
    "# Define model function which outputs predictions \n",
    "def multi_linear_model(input_data):\n",
    "    return(predictor.predict(input_data[['OverallQual','GrLivArea']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_model(multi_linear_model, print_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does this compare with the accuracy of the single variable models in the previous notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Modify the code above to add `YearBuilt` to the multilinear model and observe the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with categorical variables (Part 1)\n",
    "In order to make use of categorical data, we first need to encode it as a number. As a simple example, we'll encode the variable `CentralAir` as 0 if there is no central air conditioning, and 1 if there is central air conditioning. We can do this by using a Boolean comparison operation, and relying on the fact that `True == 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key:** We need to apply the same feature engineering to the train and test datasets. To make this easy and repeatable, we will write a function to carry out the desired encoding (`encode_data()`) each time. In this case, it encodes the `CentralAir` variable as described above and selects the `OverallQual`, `GrLivArea` and `CentralAir` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data):\n",
    "    \"\"\"\n",
    "    Create copy of input data and transform string values (Y/N) of 'CentralAir' column to Booleans,\n",
    "    return data frame with specified training columns\n",
    "    \"\"\"\n",
    "    features = data.copy()\n",
    "    features['CentralAir'] = features['CentralAir'] == 'Y'\n",
    "    return features[['OverallQual','GrLivArea','CentralAir']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression model function using the above encode_data feature engineering\n",
    "# returns the model predictions\n",
    "\n",
    "# Create features data frame and train model\n",
    "training_features = encode_data(training_set)\n",
    "predictor = linear_model.LinearRegression()\n",
    "predictor.fit(training_features, training_set['SalePrice'])\n",
    "\n",
    "# Define model function which outputs predictions\n",
    "def central_air_model(input_data):\n",
    "    input_features = encode_data(input_data)\n",
    "    return(predictor.predict(input_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluate_model(central_air_model, print_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Add whether or not the house has a pool to this model in the code above. (Look at the `PoolArea` variable).  \n",
    "Compare this model's accuracy now that the presence of a pool is a feature.  \n",
    "Did it improve it or make it worse? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with ordinal variables\n",
    "If the categories of a variable follow a clear rank, then we can label them by this rank. An example of this is the basement quality column.\n",
    "\n",
    "    BsmtCond: Evaluates the general condition of the basement\n",
    "\n",
    "       Ex\tExcellent\n",
    "       Gd\tGood\n",
    "       TA\tTypical - slight dampness allowed\n",
    "       Fa\tFair - dampness or some cracking or settling\n",
    "       Po\tPoor - Severe cracking, settling, or wetness\n",
    "\n",
    "We would encode this as Po:1, Fa:2, TA:3, Gd:4, and Ex:5.\n",
    "\n",
    "For houses without a basement (i.e. `BsmtCond is NaN`), we use a default value of 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use 'OverallQual' and 'GrLivArea', and create 'BsmtQuality' feature\n",
    "def encode_data(data):\n",
    "    \"\"\"\n",
    "    Create copy of input data and transform categories to numerical values,\n",
    "    return data frame with specified training columns        \n",
    "    \"\"\"\n",
    "    features = data.copy()\n",
    "\n",
    "    # Create dictionary to map category string to numerical value\n",
    "    bsmt_cond_map = {'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1}\n",
    "\n",
    "    # Create 'BsmtQuality' feature by mapping the numerical value to the basement condition\n",
    "    # and fill gaps where map failed - Some houses have no basement\n",
    "    features['BsmtQuality'] = features['BsmtCond'].map(bsmt_cond_map).fillna(0)\n",
    "\n",
    "    return features[['OverallQual','GrLivArea','BsmtQuality']]\n",
    "\n",
    "\n",
    "# Create features data frame and train model\n",
    "training_features = encode_data(training_set)\n",
    "predictor = linear_model.LinearRegression()\n",
    "predictor.fit(training_features, training_set['SalePrice'])\n",
    "\n",
    "# Define model function which outputs predictions\n",
    "def basement_cond_model(input_data):\n",
    "    input_features = encode_data(input_data)\n",
    "    return(predictor.predict(input_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluate_model(basement_cond_model, print_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Add to the code above the KitchenQuality as a feature: see `KitchenQual` in [data_description.txt](https://github.com/eliiza/ml-training-data/blob/master/housing_price_data/data_description.txt).\n",
    "\n",
    "Does this make the model perform better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with categorical variables (part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is no order, we use a technique called 'one hot encoding'.  \n",
    "This involves creating a new column for each category.\n",
    "\n",
    "For example, the `Electrical` variable in the housing prices dataset contains the following categories:\n",
    "\n",
    "       SBrkr\tStandard Circuit Breakers & Romex\n",
    "       FuseA\tFuse Box over 60 AMP and all Romex wiring (Average)\t\n",
    "       FuseF\t60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
    "       FuseP\t60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
    "       Mix\tMixed\n",
    "\n",
    "We would encode the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Electrical|\n",
    "|:---------|\n",
    "  |FuseA|\n",
    "  |FuseF|\n",
    "  |FuseP|\n",
    "  |Mix|\n",
    "  |SBrkr|\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|FuseA |FuseF|FuseP|Mix|SBrkr| \n",
    "|-:-|-:-|-:-|-:-|-:-|\n",
    "| 1| 0 | 0 | 0 | 0 |\n",
    "| 0|1  | 0 | 0 | 0 |\n",
    "| 0|0  | 1 | 0 | 0 |\n",
    "| 0|0  | 0 | 1 | 0 |\n",
    "| 0|0  | 0 | 0 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_electrical(electrical):\n",
    "    \"\"\"\n",
    "    Create data frame with one column per category in 'electrical' column, rows are Boolean with respect to\n",
    "    category string in electrical column.\n",
    "    \"\"\"\n",
    "    one_hot_encoding = pd.DataFrame()\n",
    "    one_hot_encoding['FuseA'] = electrical == 'FuseA'\n",
    "    one_hot_encoding['FuseF'] = electrical == 'FuseF'\n",
    "    one_hot_encoding['FuseP'] = electrical == 'FuseP'\n",
    "    one_hot_encoding['Mix']   = electrical == 'Mix'\n",
    "    one_hot_encoding['SBrkr'] = electrical == 'SBrkr'\n",
    "    return(one_hot_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_electrical(training_set['Electrical']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to use 'OverallQual' and 'GrLivArea', and one hot encode 'Electrical'\n",
    "def encode_data(data):\n",
    "    \"\"\"\n",
    "    Create copy of input data and transform categories to Boolean values,\n",
    "    return data frame with specified training columns        \n",
    "    \"\"\"\n",
    "\n",
    "    # Create one hot encoded data frame\n",
    "    electrical = encode_electrical(data['Electrical'])\n",
    "\n",
    "    # Join one hot encoded data frame and feature columns from training data\n",
    "    data = pd.concat([electrical,data[[\"OverallQual\",\"GrLivArea\"]]],axis=1)\n",
    "\n",
    "    return(data)\n",
    "\n",
    "\n",
    "# Create features data frame and train model    \n",
    "training_features = encode_data(training_set)\n",
    "predictor = linear_model.LinearRegression()\n",
    "predictor.fit(training_features, training_set['SalePrice'])\n",
    "\n",
    "# Define model function which outputs predictions\n",
    "def electrical_model(input_data):\n",
    "    input_features = encode_data(input_data)\n",
    "    return(predictor.predict(input_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluate_model(electrical_model, print_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Encode `Heating` using One Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many machine learning algorithms require all variables to be on the same scale, ideally between -1 and 1.  \n",
    "Let's compare `OverallQual` to `GrLivArea`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[['OverallQual','GrLivArea']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can transform these variables to be on the same scale using a preprocessing trick called _min/max scaling_. \n",
    "\n",
    "`MinMaxScale(X) = (X - min(X))/(max(X) - min(X))` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sklearn library has a function that can do this for us\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scale function\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Create data frame by fitting the scale function on the 'OverallQual' and 'GrLivArea' columns\n",
    "# of the training set and transforming their values as columns in the data frame\n",
    "scaled = pd.DataFrame(scaler.fit_transform(training_set[['OverallQual','GrLivArea']].astype(float)),\n",
    "             columns=['OverallQual','GrLivArea'])\n",
    "\n",
    "# Inspect the result\n",
    "scaled.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put these back to their original scale using the `inverse_transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scaler.inverse_transform(scaled),\n",
    "             columns=['OverallQual','GrLivArea']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do they match with the original data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[['OverallQual','GrLivArea']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining features\n",
    "\n",
    "We can also add new features to our model by combining two or more existing features. For example, let's\n",
    "multiply `OverallQual` by `GrLivArea`. These are often called **interaction** variables.\n",
    "\n",
    "We'll also scale our input and output. When we carry out scaling, we need to pass the scaling object to the model function, so that it can apply the same scaling process to unseen input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data,scaler = None):\n",
    "    \"\"\"\n",
    "    Create copy of input data and create new feature, scale feature and\n",
    "    return data frame with specified, scaled training columns        \n",
    "    \"\"\"\n",
    "\n",
    "    data = data.copy()\n",
    "    data = data[['OverallQual','GrLivArea']]\n",
    "    # New feature is (unscaled) product of selected columns\n",
    "    data['QualAreaInteract'] = data['OverallQual'] * data['GrLivArea']\n",
    "\n",
    "    # Convert to float data type for scaling process\n",
    "    data = data.astype(float)\n",
    "\n",
    "    # Create and fit scaler if no scaling function is given\n",
    "    if(not scaler):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(data)\n",
    "\n",
    "    # Create data frame with scaled features only    \n",
    "    pd.DataFrame(scaler.transform(data), columns = ['OverallQual','GrLivArea','QualAreaInteract'])\n",
    "    return(data,scaler)\n",
    "\n",
    "\n",
    "# Create features data frame and train model    \n",
    "training_features, training_scaler = encode_data(training_set)\n",
    "predictor = linear_model.LinearRegression()\n",
    "predictor.fit(training_features, training_set['SalePrice'])\n",
    "\n",
    "# Define model function which outputs predictions, using the training_scaler from above\n",
    "def interaction_model(input_data, scaler = training_scaler):\n",
    "    input_features,returned_scaler = encode_data(input_data,scaler)\n",
    "    predictions = predictor.predict(input_features)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "evaluate_model(interaction_model, print_result=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition Exercise (optional)\n",
    "\n",
    "Build a multiple linear model to achieve as low score as possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
